{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa13e3f7-b2c9-4a0c-ba7c-289acee30f9c",
   "metadata": {},
   "source": [
    "## Parsing FAIR evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb53978-2683-43e7-8f6d-8eadcfa4705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b88d8ec-6220-4919-8e67-63dd27515bb4",
   "metadata": {},
   "source": [
    "### Sample data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f38952-9ee0-4610-abb6-e9f8c1ad56de",
   "metadata": {},
   "source": [
    "|DOI | Example | File Name |\n",
    "|---|---|---|\n",
    "| https://doi.org/10.3233/FAIA200871 | Example 1: Publication metadata | fair_metrics_1_publication.json |\n",
    "| https://doi.org/10.1145/3184558.3191543 | Example 2: Publication metadata  | fair_metrics_2_publication.json |\n",
    "|https://doi.org/10.5281/zenodo.8148685| Example 3: Software metadata | fair_metrics_3_software.json |\n",
    "|https://doi.org/10.34894/Q80QUE| Example 4: Dataset metadata | fair_metrics_4_dataset.json |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a21578-56d3-4a74-a67b-afc1ccd699be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file names\n",
    "file_data = [\n",
    "    {\n",
    "        \"DOI\": \"https://doi.org/10.3233/FAIA200871\",\n",
    "        \"File Name\": \"fair_metrics_1_publication.json\"\n",
    "    },\n",
    "    {\n",
    "        \"DOI\": \"https://doi.org/10.1145/3184558.3191543\",\n",
    "        \"File Name\": \"fair_metrics_2_publication.json\"\n",
    "    },\n",
    "    {\n",
    "        \"DOI\": \"https://doi.org/10.5281/zenodo.8148685\",\n",
    "        \"File Name\": \"fair_metrics_3_software.json\"\n",
    "    },\n",
    "    {\n",
    "        \"DOI\": \"https://doi.org/10.34894/Q80QUE\",\n",
    "        \"File Name\": \"fair_metrics_4_dataset.json\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cef368f-eae6-4fae-967f-e119f65c19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Metadata FAIR metrics\n",
    "attributes = [\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/f1-metadata-identifier-persistent\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/f1-metadata-identifier-unique\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/a1-metadata-authorization\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/a1-metadata-protocol\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/f2-structured-metadata\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/f1-data-identifier-persistent\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/f3-metadata-identifier-in-metadata\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/i3-metadata-contains-outward-links\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/r1-includes-license\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/f2-grounded-metadata\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/a1-data-protocol\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/a1-data-authorization\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/a2-metadata-persistent\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/f3-data-identifier-in-metadata\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/i1-data-knowledge-representation-structured\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/i1-metadata-knowledge-representation-structured\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/f4-searchable\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/i1-data-knowledge-representation-semantic\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/i2-fair-vocabularies-known\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/i1-metadata-knowledge-representation-semantic\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/r1-includes-standard-license\",\n",
    "    \"https://w3id.org/fair-enough/metrics/tests/i2-fair-vocabularies-resolve\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88708591-7e4c-4fb2-ac25-a277e321435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/hh5hqvzj7szdjc24hlsbn00h0000gn/T/ipykernel_59398/1652833171.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(df)\n",
      "/var/folders/s8/hh5hqvzj7szdjc24hlsbn00h0000gn/T/ipykernel_59398/1652833171.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(df)\n",
      "/var/folders/s8/hh5hqvzj7szdjc24hlsbn00h0000gn/T/ipykernel_59398/1652833171.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(df)\n",
      "/var/folders/s8/hh5hqvzj7szdjc24hlsbn00h0000gn/T/ipykernel_59398/1652833171.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(df)\n",
      "/var/folders/s8/hh5hqvzj7szdjc24hlsbn00h0000gn/T/ipykernel_59398/1652833171.py:49: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  all_data.to_excel(\"FAIR_metrics_report.xls\", index=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through each file\n",
    "for file_info in file_data:\n",
    "    with open(f\"data_sample/{file_info['File Name']}\", \"r\") as file:\n",
    "        data_sample = json.load(file)\n",
    "    \n",
    "    rows = []\n",
    "\n",
    "    for attribute in attributes:\n",
    "        metric_results = data_sample[\"contains\"].get(attribute, [])\n",
    "        if not metric_results:\n",
    "            continue\n",
    "\n",
    "        metric_result = metric_results[0]\n",
    "        value = metric_result.get(\"http://semanticscience.org/resource/SIO_000300\", [{}])[0].get(\"@value\", None)\n",
    "        comment = metric_result.get(\"http://schema.org/comment\", [{}])[0].get(\"@value\", None)\n",
    "\n",
    "        # Extracting the last prompt from the comment\n",
    "        if comment:\n",
    "            matches = re.findall(r\"(INFO|SUCCESS|FAILURE): \\[\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\] .+\", comment)\n",
    "            if matches:\n",
    "                comment = matches[-1]  # Taking the last match\n",
    "\n",
    "        # Build each row\n",
    "        rows.append({\n",
    "            \"_id\": data_sample[\"_id\"],\n",
    "            \"subject\": data_sample[\"subject\"],\n",
    "            \"created_at\": data_sample[\"created_at\"],\n",
    "            \"name\": data_sample[\"name\"],\n",
    "            \"fair_metric\": attribute.split(\"/\")[-1],  # Get the last part of the URL for a cleaner metric name\n",
    "            \"value\": value,\n",
    "            \"comment\": comment,\n",
    "            \"DOI\": file_info[\"DOI\"],  # Adding DOI to the dataframe\n",
    "        })\n",
    "    \n",
    "    # Convert rows to DataFrame and append to the overall dataframe\n",
    "    df = pd.DataFrame(rows)\n",
    "    all_data = all_data.append(df)\n",
    "\n",
    "# Export the combined dataframe to an excel file\n",
    "all_data.to_excel(\"FAIR_metrics_report.xls\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8aabe-d31b-4bf1-a104-72d2c50bd739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f400db-9f6c-4cc5-9d15-e31d68273e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to fetch fair evaluations\n",
    "# def fetch_fair_evaluation(doi):\n",
    "#     url = \"https://api.fair-enough.semanticscience.org/evaluations\"\n",
    "#     headers = {\n",
    "#         \"accept\": \"application/json\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "#     data = {\n",
    "#         \"subject\": doi,\n",
    "#         \"collection\": \"fair-enough-metadata\"\n",
    "#     }\n",
    "#     response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to fetch data for DOI: {doi}. Status code: {response.status_code}\")\n",
    "#         return None  # Return None for failed requests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
